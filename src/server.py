import socket
import threading
from http.server import BaseHTTPRequestHandler, HTTPServer
import json

class MLRequestHandler(BaseHTTPRequestHandler):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ HTTP –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è ML API"""
    
    def do_GET(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ GET –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if self.path == '/health':
            self._send_response(200, {'status': 'healthy'})
        elif self.path == '/metrics':
            self._send_response(200, self._get_metrics())
        else:
            self._send_response(404, {'error': 'Not found'})
    
    def do_POST(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ POST –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        if self.path == '/predict':
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            
            try:
                data = json.loads(post_data.decode('utf-8'))
                prediction = self.server.ml_model.predict(data)
                self._send_response(200, {'prediction': prediction})
            except Exception as e:
                self._send_response(400, {'error': str(e)})
    
    def _send_response(self, status_code, data):
        # –û—Ç–ø—Ä–∞–≤–∫–∞ JSON –æ—Ç–≤–µ—Ç–∞
        self.send_response(status_code)
        self.send_header('Content-Type', 'application/json')
        self.end_headers()
        self.wfile.write(json.dumps(data).encode('utf-8'))

class MLWebServer(HTTPServer):
    """–í–µ–±-—Å–µ—Ä–≤–µ—Ä –¥–ª—è ML –º–æ–¥–µ–ª–µ–π —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
    
    def __init__(self, host, port, ml_model):
        super().__init__((host, port), MLRequestHandler)
        self.ml_model = ml_model
        self.request_count = 0
        
    def serve_forever(self):
        print(f"üöÄ ML Web Server –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://{self.server_address[0]}:{self.server_address[1]}")
        super().serve_forever()